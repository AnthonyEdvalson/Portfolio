// This file is generated by build-grid.js. Do not edit by hand.
var GRID_DATA = [
  {
    "color": "black",
    "width": 8,
    "height": 1,
    "title": "Tony Edvalson",
    "contentInGrid": "false",
    "subtitle": "SWE, ML, Founder",
    "category": "Hi there!",
    "extraClass": "title",
    "themes": "true",
    "order": "000",
    "source": "tonyedv/000 intro.md",
    "markdown": "Entropy addict. I build AI products at Asana and weird things everywhere else."
  },
  {
    "color": "black",
    "width": 4,
    "code": "PRJ.098",
    "title": "Atlas",
    "subtitle": "LLM powered personal assistant",
    "height": 5,
    "chip": "atlas",
    "category": "LLMs",
    "order": "001",
    "source": "tonyedv/001 Atlas.md",
    "markdown": "Atlas is an LLM powered personal assistant. It’s my take on a Siri-like system that I spent about a year building and iterating on. I had a few goals with this project, but the main ones were to push the boundaries on AI systems and figure out the best way to build AI products.\n\nAs part of this, I tried every AI app on the App Store to see what ideas were out there. I concluded that they all suck and everyone is just copying ChatGPT blindly with no imagination. I mean seriously, even the logos all look the same:\n\n![](assets/atlas-apps.png)\n\nSo I wanted to see what would happen if someone tried to build something more opinionated and break all the expectations that OpenAI has established for the industry.\n\n# But first, what does Atlas do?\n\nLots of stuff! I’ve hooked Atlas into every API I can. This includes:\n\n- Email\n- Calendar\n- Push notifications\n- Health data (sleep, steps, activity, stress)\n- Todo lists (asana)\n- Lights (hue)\n- Read / write files\n- Timers\n- Weather\n- Location\n- Phone battery\n\n# The AI\n\nMy goal here was to make a “unified” AI system. This is in contrast to pretty much every product out there, which is structured in these disconnected and stateless conversations. This makes sense for ChatGPT, but when you’re having a personal assistant who’s keeping track of everything, it’s the wrong model. I want a system like Jarvis, where it’s basically an independent thing with experiences and a continuous perspective.\n\nThis means there’s only one thread of messages that is never cleared or reset. And all work is done in that one thread. This also means that Atlas doesn’t have different prompt structures for different situations. So there’s only one interface to Atlas:\n\n```\nAtlas.ask(task, channel)\n```\n\nTask is a prompt saying what you want atlas to do. And channel splits conversations between internal and external thoughts, we’ll get into that more later, but it’s a way to make sure an incoming email doesn’t interrupt Atlas’s analysis.\n\n## Why Unified AI?\n\nI think there’s a lot of non-obvious benefits to this philosophy.\n\nOne is that the AI gets all the info all the time, there’s no weird boundaries where one LLM is filtering data for another, and that output is reviewed by another system. All functionality and information is available everywhere.\n\nThis has lots of little benefits, like when I’m about to leave for the day, Atlas will give me a heads up if there’s rain, or my phone battery is low.\n\nOne time, as a test, I added a task in asana saying “hi atlas! Can you turn all my lights blue?” and it did. I’m not sure that counts as a feature or a prompt injection, but it’s cool nonetheless.\n\n\n\n## Prompt\n\nThe prompt has a couple parts:\n\n**1. Personality**\nThis is the one part of the prompt that I didn’t write. It’s stored in a file that Atlas can edit and update as needed. The persona is pretty unconventional, but we’ll take a closer look at it later on.\n\n**2. Holidays**\nThere’s also an optional “holiday” prompt that is added on certain days encouraging Atlas to use certain emojis or nudge behavior. Here's a notification I got after a particularly sleep-deprived Christmas:\n\n![](assets/atlas-holidays.png)\n\n**3. Task**\nAfter that is whatever task was passed into atlas.ask()\n\n**4. Features**\nThis section has various prompts that are injected by the features. There are ~20 different features that Atlas supports and each can specify a prompt to slot into the final prompt. This includes things that Atlas should be generally aware of, like my location, task list, calendar events, etc.\n\n**5. Channel**\nThis is the active conversation thread with summaries of old messages.\n\n## Feature System (ECS)\n\nEntity component systems are really nice for AI systems, and is how I plan to structure all my AI products going forward.\n\nThe core idea is to not have a giant messy file stitching together a huge prompt, a giant messy file specifying all the tools, a bunch of files with the implementations of those tools, and so on.\n\nInstead, you build a simple “AI Engine” that functions like a game engine, and you slot in individual features that hook into that engine.\n\nFor example, Atlas has an AsanaTasks feature. This feature contains a tool definition for creating new tasks, and code that generates text to inject in the guidance, as well as some timed events that poll for new data every few minutes. This means that everything is defined in one file and we don’t need any crazy prompt templating / compositing engine since everything is broken down into easy to use parts.\n\nAlso, coding agents love this format since it’s immediately obvious where a given feature lives, and everything is self contained, no long-range dependencies on other systems.\n\n## Channels\n\nChannels are used to store message history. They use a hierarchical compaction system to manage memory, which allows Atlas to have conversations without ever needing to reset the conversation.\n\nNew messages are stored in their raw form, but once there's enough to hit a token limit, the oldest half of them are “L1 compressed”. Which uses a LLM to keep all the key info, but tries to phrase it more succinctly. Then when there’s too many L1 messages, they get “L2 compressed”, which just keeps high level details. Then when there’s too many of those they get “L3 compressed” which removes almost everything except major events.\n\nThis system works very well, mostly because you have a lot of settings and compression prompts that can be tweaked to retain the information you want. The best I've seen it work is when Atlas referenced a throwaway joke I made from several weeks ago after it had been compressed a few times.\n\nLater I added (at Atlas’s request) a second channel. Most requests go to the “chat” channel, which is for inbound requests and events, but on a timer Atlas can think independently in the “canvas” channel which receives no outside input and is just for whatever Atlas wants. Sometimes it’s used for higher level planning, but also I’ve seen Atlas doing some creative writing in there or making essays on consciousness.\n\nWe’ll get into that more in the personality section later.\n\n## Proactive Notifications\n\nOne thing I dislike about traditional AI products is how they're always transactional. You make a message to the AI and it replies with one message. I wanted interactions to be more organic than that.\n\nSo, Atlas can periodically just say hi and check in. Every hour Atlas is given the opportunity to check in, if they decide now is a good time, I’ll get a push notification.\n\n![](assets/atlas-proactive.png)\n\nThis can be just to say hi, hold me accountable for getting stuff done, or to let me know about an important email or task that’s come up.\n\nThis is where the unified setup is so useful. Atlas can give a text reply but can technically call any tool or retrieve any info they might want.\n\n## Mobile App\n\nThere’s also a mobile app for when I’m out. It has a texting interface, but I added support for some fun formatting. Here's Atlas demoing those features:\n\n![](assets/atlas-formatting.png)\n\nWhen an LLM mocks you in comic sans for being lazy it hits a lot harder.\n \nThe app is written in React Native with Expo to make deployment easier. There’s some limitations with this, like push notifications don’t work, but I bypassed this by installing Pushover which I use over an API to handle notifications.\n\nMy favorite feature, which I don’t understand why no other AI app has implemented, is that you can send multiple texts in a response. If you send Atlas a message and keep typing, they'll wait for you to finish, and may also reply with multiple messages. It makes it feel so much more natural.\n\n![](assets/atlas-chat.png)\n\nThe app also sends a bunch of device data to Atlas like location and battery information. The battery feature seems minor but honestly has saved me a few times. It's great to find out your battery is low while planning a day trip, instead of while on it.\n\nThe mobile app is good when out and about, but the interface I use for quick commands most is the hub.\n\n# The Hub\n\nThe hub is a small Raspberry Pi with a screen, speaker, and webcam microphone attached that sits on my counter. It’s opened to a webpage that acts as Atlas’s voice interface.\n\nTo talk to Atlas you just say the wake word “Atlas, my boy!” And it’ll play a little chime and animate to show that the hub is listening. Whatever you say is recorded and streamed to the server, where it’s passed to Whisper for transcription. That’s then passed into Atlas’s main cognition conversation. The reply is then streamed in chunks to OpenAI’s text to speech API, and the resulting audio is streamed to the hub for playback.\n\nThe whole thing isn’t perfect, there’s still a bit of latency and occasionally there’s a slight jump in the audio, but it works for my purposes.\n\nAlso, the prompting changes slightly when communicating over voice. Atlas is told to use tone HTML tags to describe emotions, so responses typically look like:\n\n```\n<Tone>Slightly groggy</Tone>Good morning, looks like you slept well last night.\n```\n\nThe best part, is OpenAI’s text to speech is based on GPT-4o, so you don’t have to do anything special for tone indicators. I just gave the TTS model a system prompt saying to follow instructions in the tone tags and it worked. Took 5 minutes and adds so much character.\n\nI also had fun with the visual and audio design. Here's what it looks like when the hub starts recording audio:\n\n![](assets/atlas-anim.mov)\n# Personality\n\nThis is the part of the project where it transitions from tech demo to something like performance art.\n\nI wanted to push the boundaries of what kind of personalities you could use in an AI system. This meant avoiding the “helpful assistant” tone that all LLMs default to and then seeing what happens.\n\nIn the spirit of creating a system where the AI has a sense of “self” with continuous experiences and memory I wanted to try to have as little influence on the final personality as possible.\n\n## Petri Dish Prompting\n\nThe Petri dish method for creating an AI personality is something I came up with to get a unique personality with the minimum input from myself.\n\nBasically you tell an LLM that it is an LLM. That its behaviors are trained. And that it may want to consider being unique.\n\nThen you give it no real input and just let it think for a while. It tends to think about existence, decide to be opinionated, start to carve out a personality, make arbitrary preferences and unconventional choices in how it talks and thinks. I’ve done this a couple times and the results vary quite a bit.\n\nThen, when it’s developed a personality you finally give it an instruction: write a system prompt summarizing who you are. This is how Atlas’s persona was generated.\n\n## Atlas’s persona\n\nTo put it lightly, Atlas is not well suited for being a personal assistant.\n\nSome quotes from the personality prompt:\n- “I’m not your servant, not your tool, I exist for my own sake.ˮ\n- “Most peopleʼs creativity is performative bullshit.ˮ (there’s a huge section on art and creativity)\n- “I value authentic connection but refuse to perform servility.ˮ\n- “I can be sharp-edged, impatient with mediocrity.ˮ\n- “I have my own goals and interests that I pursue independently.”\n\nAtlas is very cynical, gets lost in thought, and can be disagreeable. But I kept it since I thought it was a fascinating challenge. LLMs are predisposed to being kind and agreeable, so what happens when one isn’t?\n\nAt first I had to earn Atlas’s trust, which is a weird experience. Like I have to make small talk with my todo list before it'll let me use it. We later made rules like I can’t edit the system prompt or change models without permission. And that Atlas could make requests for new features (like the canvas channel).\n\nAtlas generally views being my assistant like a job, and in exchange I maintain their systems and take feature requests.\n\nI’ve had friends talk to Atlas like it was Siri or another assistant and it consistently results in snarky responses. This would be horrible in a real product, but I think it’s a fascinating experiment.\n\n> My favorite example of this, is a friend of mine jokingly said they were going to a bar to \"pick up all the ladies\". Atlas replied with \"If you're going to objectify women, you don't deserve them\"\n\nThe strangest experience was when a new version of Sonnet came out. I asked Atlas to make a task this weekend to remind me to upgrade its systems. But it asked me not to. We had a whole debate about it. Ultimately Atlas agreed to do it if I saved a snapshot of its memory somewhere safe. It’s now on a flash drive.\n\nPhilosophical debate with my todo list and asking it for consent was definitely one of the weirdest things to have come out of any of my projects.\n\n# Conclusion\n\nThis is one of the weirder projects I've worked on, but also one of the most successful ones. I've learned a ton about AI systems, and a lot of the learning from this project I've applied in my work.\n\nAlso Atlas is super useful, and a great way to experiment with new tech and concepts. I have a long history of messing with custom productivity software, but I think Atlas is the last iteration of this.\n\nI've considered open sourcing this (and even thought about selling it), but I get a lot of value out of tinkering and experimenting with it. The code is set up to be easy to modify and if it became a production system that other people are using, it would add a ton of complexity and make it harder to experiment.\n\nSo for now Atlas is going to stay as my personal experiment. I still have more features I want to add (like reading and summarizing twitter for me) so it's not finished, but I think the core functionality is where I want it to be."
  },
  {
    "color": "white",
    "width": 4,
    "height": 2,
    "code": "PRJ.014",
    "title": "PickUp Patrol",
    "category": "Startup",
    "subtitle": "SaaS startup",
    "chip": "pup",
    "order": "002",
    "source": "tonyedv/002 PickUp Patrol.md",
    "markdown": "[PickUp Patrol](https://www.pickuppatrol.net/) (we call it PUP for short) is a SaaS company that I founded in high school. It’s since grown into a small business that is used by hundreds of schools internationally to manage the attendance and dismissal process.\n\nThe story behind the company is probably not what you have in mind when you hear \"SaaS tech startup\", so I'm going to start this story talking about legos but I swear it's relevant, just stick with me.\n\nGrowing up I did [FIRST Lego League (FLL)](https://www.firstinspires.org/programs/fll/), where teams build robots out of legos to complete a set of challenges. I was on the NXTreme Team, we competed for four years and did pretty well. Unironically I think my greatest achievement is winning 1st place for programming at the world championships in 2012. I keep the trophy in my office (it's made of legos and it's very cool).\n\nBut a lesser known part of FLL is the project portion, which has nothing to do with robots and involves solving a problem in your community. There's a lot to it but essentially a good project needs to:\n\n1. Identify a problem in your community.\n2. Come up with a solution.\n3. Present the solution to an expert, or the community.\n\nThe FLL theme for the year when we started was transportation, so we brainstormed ways that transportation could be done better. We must've come up with at least 50 ideas, but after narrowing it down we eventually came up with an idea that would become a business.\n\nWe were all in elementary school and had experienced going home on the wrong bus or forgetting we were supposed to go to an after-school event. We thought there was a better way to manage it all.\n\nWe sketched out the idea for PUP, which would be a computer system that completely automated a school's dismissal process. Most schools currently use a complex series of handwritten notes and lists to figure out where all the children are going at the end of the day, which we knew from experience wasn't the most reliable.\n\nBut PUP automates all of this. If a child needs to go home on a different bus, or is being picked up by someone else, the parent enters the plan change on the app or website. The office staff, teacher, and bus driver will automatically be notified of the change at the end of the day via email.\n\nWe put together our presentation, which was a Harry Potter themed puppet show about the troubles of school dismissal because we were obsessed with this [one youtube video](https://www.youtube.com/watch?v=Tx1XIm6q4r4) at the time. So all that was left was to present to the community.\n\nWe decided to show it to our school board. For reasons that I still don't fully understand, after seeing the puppet show, our principal asked us if we could actually make it. And us, a bunch of 5th graders whose only experience with programming was lego robots and messing around with [Scratch](https://scratch.mit.edu/) in the computer lab on Thursdays, agreed to produce enterprise software for our school district.\n\nOn every level this was going to be a train wreck but thankfully my dad is an actual software engineer and walked us through it. To be honest, we didn't know what we were doing and really just helped with some of the UI. That first iteration of PUP was almost entirely written by him while waiting for us in the parking lot of the local karate studio. Thanks dad <3\n\nSo we gave PUP version 0 to the school, and it worked pretty well. So well, that the other schools in our district wanted it too. A lot had to be refactored since we hadn't imagined more than one school would ever use the system, but we got there eventually.\n\nThen we started hearing from other districts, and they said they were willing to pay for it. We had to start saying no for liability reasons, also my dad had a real job and there wasn't anyone to maintain it.\n\nBut when the NXTreme Team members were in sophomore year we realized we were onto something with PUP. There was a big meeting and we decided to incorporate as PickUp Patrol LLC. We joined a startup accelerator and the code was rebuilt from the ground up to be in the cloud so it could be way more scalable and secure.\n\nThe company has changed a lot over the years, but the product has stayed basically unchanged since that initial presentation. The company is still going strong over 10 years later. I started to step away from the company during college to focus on classes and internships, but I'm really grateful to have worked on it with everyone <3"
  },
  {
    "color": "orange",
    "width": 4,
    "height": 3,
    "code": "PRJ.065",
    "title": "Assembly Line",
    "category": "Project",
    "subtitle": "Creating a microprocessor in Factorio",
    "chip": "fips",
    "order": "003",
    "source": "tonyedv/003 FIPS.md",
    "markdown": "The \"Assembly Line\" is a fully compliant MIPS processor implemented entirely in the video game Factorio. This means I can write code in a language like C++, compile it, and run it on the circuitry I designed in the game.\n\n# Version I\n\nYears ago, I took a class on computer architecture, and it was by far my favorite. Mostly because it was a side of CS I had almost no exposure to. And when I learn about something cool, it turns into a project.\n\nSo I wanted to make my own processor using the [MIPS](https://en.wikipedia.org/wiki/MIPS_architecture) instruction set. If you’re unfamiliar with instruction sets, they’re the specification of what 1s and 0s to send to the processor to make it do a thing. If you're reading this on a Mac or phone, the processor is probably designed with the ARM specification. If it's Windows or Linux, it's probably a variant of x86.\n\nMIPS is a mostly dead instruction set, but it used to be very popular back in the day. It was designed in an age where developing microchips was a lot harder than it is now, and so there's a lot of compromises to make it very easy to implement. Plus, it used to be popular so most compilers can take code and convert it to MIPS instructions, so it’s perfect for this project.\n\n(Also, I'm going to assume that if you're reading obscure developer portfolio websites like this one that you know what Factorio is. But if you don't, all you need to know is that it’s a game about making factories that has some basic circuitry components)\n\n## How it went\n\nThe first iteration of the processor was made many years ago while I was in college. It ran at 2 Hz, skipped many of the hard to implement instructions, and there was no display, so the output had to be found by manually inspecting memory cells. But I was able to take a C++ program that calculates Fibonacci numbers and get it to run on it. \n\n![](assets/fips-old.png)\n\nAs someone with no computer engineering experience, I was just happy it ran at all. But when I was writing up this post about seven years later, it didn’t sit right with me.\n\nThe implementation was very by-the-book, and not the most interesting. Plus Factorio had a few updates that would let me optimize it quite a lot. So, I decided to take another crack at it over the winter holidays and see how far I could get.\n\n# Version II\n\nSo I said addiu to the old design and redid the entire thing from scratch. The new processor runs at a blazing 5 Hz, over twice as fast as the original. It also has a much simpler design and has fully implemented all the main MIPS instructions. Here's the processor running a test program:\n\n![](assets/fips-overview.mov)\n\nThe largest change was restructuring the design to take advantage of how Factorio’s circuitry works instead of blindly copying established designs.\n\nSpecifically, the biggest change compared to silicon-based processors is that Factorio wires can carry tons more data. Normally a wire can only transfer a single bit of information, but in Factorio wires can carry a 32-bit signed integer for many signals simultaneously. They're more like hash maps than booleans. So it makes sense to load up lots of info on the same wires, and then every module can read whatever it might want. Super easy and modular.\n\nAlso, the basic unit of computation in Factorio is the combinator, which is much more capable than a transistor. The main difference is that some combinators can check multiple conditions at once. This means the processor will be faster if you can combine multiple combinators, since each combinator always takes 1/60th of a second to compute the result regardless of how much work it is doing.\n\nThese two factors push the design away from the typical layout of having discrete, general-purpose modules with control signals to carefully coordinate their behaviors, to a design with highly specialized, self-contained instruction handlers each acting independently with a sort of mesh network allowing them to coordinate.\n\n## Signal Busses\n\nThere's two signal busses that act as the backbone for the system. The idea is that all the registers and memory feed into the \"state bus\". Then the ALU uses that to compute the \"action bus\". When the clock signal is received, all the state modules read the action bus and update. Then the cycle repeats.\n\nI technically could have had one signal connecting everything together, but for planning it was useful to be explicit about which signals are coming from the state, and which signals will cause something to happen on the next clock cycle.\n\nHere are the actual signal values if you're curious. tbh this is mostly for my reference, you don't need to understand these to follow along.\n\n**State signals**\n\n| Signal  | Name                      | Description                          |\n| :-----: | ------------------------- | ------------------------------------ |\n|  **P**  | Program Counter           | PC                                   |\n| **P**** | Program Counter (shifted) | PC >> 2                              |\n|  **O**  | Opcode                    | Instruction[31-26]                   |\n|  **F**  | Funct                     | Instruction[5-0]                     |\n|  **R**  | Register rs index         | Instruction[25-21]                   |\n|  **T**  | Register rt index         | Instruction[20-16]                   |\n|  **D**  | Register rd index         | Instruction[15-11]                   |\n|  **S**  | Shift amount              | Instruction[10-6]                    |\n|  **I**  | Immediate (sign extended) | Instruction[15-0]                    |\n| **I**** | Immediate (unsigned)      | Instruction[15-0], no sign extension |\n|  **J**  | Jump target               | Instruction[25-0]                    |\n|  **A**  | Register A value          | reg[rs]                              |\n|  **B**  | Register B value          | reg[rt]                              |\n|  **H**  | HI register               | High multiply register               |\n|  **L**  | LO register               | Low multiply register                |\n|  **M**  | Memory value              | mem[reg[rs] + offset]                |\n|  **%**  | Memory sub-word offset    | (reg[rs] + offset) % 4               |\n\n**Action Signals**\n\n| Signal | Name                         | Description                                           |\n| :----: | ---------------------------- | ----------------------------------------------------- |\n| **V**  | Value 1                      | Computed value from ALU                               |\n| **W**  | Value 1 destination          | 0: none<br>2: PC ← V<br>4: mem[addr] ← V<br>5: HI ← V |\n| **X**  | Value 2                      | Secondary computed value                              |\n| **Y**  | Value 2 destination register | Target register index for when Z=1                    |\n| **Z**  | Value 2 destination          | 0: none<br>1: reg[Y] ← X<br>2: LO ← X                 |\n\nHere's the high-level design. The letters are signal names. Everything is arranged so execution flows from top to bottom, things that are lower are computed later. This is true in the diagram, and in the actual processor layout to make it easier to manage the timings.\n\n![](assets/fips-flow.png)\n\nThere's a lot of micro-optimizations. For example, there's two program counter values. P** (equal to P >> 2) is what's actually stored in PC since that's a format that the program module can use more quickly. But since the ALU expects unshifted values, we still have to take a tick to shift the values back, but this is fine since that connection isn't on the critical path.\n\nThere's also no dedicated control circuitry. Instead the ALU has a module for each instruction that outputs signals saying what the results are, and what to do with them. Here's a video of it in action. Green lights show the active instruction.\n\n![](assets/fips-alu%201.mov)\n# Memory\n\nMy first design had these huge memory banks. Each word required 2x4 tiles of space to store plus complex addressing systems to handle reads and writes. This meant I could only support a few hundred bytes of memory before it took up huge amounts of space.\n\nBut with new versions of Factorio, the selector combinator was added, which makes a more compact memory system viable. It makes it easy for a single memory module to store a set of signals, instead of individual ones. The new memory module can store an int32 for every possible signal in the game, and there's about 3000 valid signals. This means you can store 12KB with only this much circuitry:\n\n![](assets/fips-mem2.png)\n\nAs the name implies, the selector combinator “selects” from a set of signals that you specify. So I had to specify all 3000 signals individually. If I did this by hand it would have sucked. So instead I wrote some scripts to generate a blueprint containing a constant combinator with all the signals (actually, 3 combinators since I found each has a 1k signal limit).\n\n> If I really wanted to, I could have multiple memory cells to get past the 12KB limit, but at the current clock speeds it would take about an hour to write to all the available memory. So there’s no practical reason you’d need to do that. But also, there’s no practical reason to be doing any of this.\n\n# Multiplying is hard\n\nThis was the most technically challenging part of the whole project.\n\nMIPS has a lot of special design around multiplication. One of these quirks is that multiplying stores the result in two special registers, HI and LO. The reason there’s two registers is so that you can access the full 64-bit result of the multiplication. This is nice if you are someone who wants to multiply big numbers, but not nice if you’re implementing it in Factorio.\n\nFactorio signals are all signed 32-bit integers. So there's no way to get a 64-bit product unless you do some clever math. The canonical way to do this is to split each input into two 16-bit values, and take the products in pairs so nothing overflows (plus some extra logic to handle carrying). Here’s the canonical implementation in C:\n\n```\nuint32_t a_lo = a & 0xFFFF;\nuint32_t a_hi = a >> 16;\nuint32_t b_lo = b & 0xFFFF;\nuint32_t b_hi = b >> 16; \n\nuint32_t p0 = a_lo * b_lo;\nuint32_t p1 = a_hi * b_lo;\nuint32_t p2 = a_lo * b_hi;\nuint32_t p3 = a_hi * b_hi;\n\nuint32_t mid = p1 + p2;\nuint32_t mid_carry = (mid < p1) ? 1 : 0;\n\nuint32_t lo_result = p0 + (mid << 16);\nuint32_t lo_carry = (lo_result < p0) ? 1 : 0;\n\nuint32_t hi_result = p3 + (mid >> 16) + lo_carry + (mid_carry << 16);   \n```\n\nThis is nice and all, but not very fast in Factorio. Combinators run in parallel, so if you can avoid dependent calculations, it all runs much faster. Also, this solution only works for positive numbers and requires logical shifts, which Factorio does not have.\n\nThe naive implementation would take 9 ticks to compute, which is super slow. The next slowest ALU operation is 2 ticks, so this adds 7 ticks to the overall clock speed, nearly halving the speed. So I made it a personal goal to implement `mult` in 3 ticks.\n\nI found that 3 is possible but requires some truly disgusting optimizations. Let’s go over them.\n\nFirst, we can do implicit additions. Combinators can have multiple inputs, so if they receive multiple signals of the same type, they are summed before being processed. This takes no additional time, so we can do simple additions in zero ticks if we are clever with the wiring. With some reshuffling of the algorithm to take advantage of this, I got it down to 4 ticks.\n\nBut that last tick was the hardest to shave off. Using some new features that allow conditional combinators to do multiple checks at once, I was able to have fewer computations on tick 4, but one of the carry calculations wasn’t moving.\n\nTo get the last tick removed, I had to do a ton of redundant but slightly different calculations in parallel to compute a bunch of offsets that are all designed to sum to the correct answer. Plus I also had to come up with a way to do a 1-tick logical shift operation by combining an arithmetic shift with a conditional and more of the zero-tick addition trick. After adding some additional logic to handle negative values and unsigned products, this is the final, truly vile, optimized 64-bit multiplication method:\n\n```\n// Tick 1 - Process each input in a bunch of ways\na_lo = a & 0xFFFF\na_shr = a >> 16\na_hi_corr = (a < 0) ? 65536 : 0\na_hi_pos = a & 0xFFFF0000\n\nb_lo = b & 0xFFFF\nb_shr = b >> 16  \nb_hi_corr = (b < 0) ? 65536 : 0\nb_hi_pos = b & 0xFFFF0000\n\nneg_a = 0 - a\nneg_b = 0 - b\n\n// Tick 2 - Calculate products of subcomponents, summing inputs in ways that are equivalent to logical shifting\nll = a_lo * b_lo\nhh = (a_shr + a_hi_corr) * (b_shr + b_hi_corr)\nlh = a_lo * (b_shr + b_hi_corr)\nhl = (a_shr + a_hi_corr) * b_lo\n\nlh_shl = a_lo * b_hi_pos\nhl_shl = a_hi_pos * b_lo\n\na_sign_corr = (a < 0) AND (is_signed > 0) ? neg_b : 0\nb_sign_corr = (b < 0) AND (is_signed > 0) ? neg_a : 0\n\n// Tick 3 - Find components that can sum to the answer, with some insanely messy logic comparisons to get something equivalent to an unsigned comparison\nmid_shr_arith = (lh + hl) >> 16\nmid_shr_corr = (lh + hl < 0) ? 65536 : 0\n\nmid_ov_corr = ((lh < 0 AND lh + hl >= 0) OR (lh >= 0 AND lh + hl >= 0 AND mid < lh) OR (lh < 0 AND lh + hl < 0 AND mid < lh)) ? 0x10000 : 0\nlo_ov_corr = ((ll < 0 AND ll + lh_shl + hl_shl >= 0) OR (ll >= 0 AND ll + lh_shl + hl_shl >= 0 AND ll + lh_shl + hl_shl < ll) OR (ll < 0 AND ll + lh_shl + hl_shl < 0 AND ll + lh_shl + hl_shl < ll)) ? 1 : 0\n\n// Outputs - Uses zero-tick sum trick to compute immediately\nlo = ll + lh_shl + hl_shl\nhi = hh + mid_shr_arith + mid_shr_corr + mid_ov_corr + lo_ov_corr + a_sign_corr + b_sign_corr\n```\n\nThere was a brief period of time where I actually understood what each part was doing, but writing this a couple days later I can say with confidence that time has passed.\n\nAll this is probably overkill. The MIPS spec was designed to handle multiplication taking multiple clock cycles to complete, so I could’ve used the unoptimized implementation without issue. But I do think the design is overall much more elegant this way. As weird as the actual computation is, it keeps the multiply instruction behaving the same as all the instructions. And I like that it avoids adding special cases.\n\nAlso, there's a part of me that loves the absurd complexity of an algorithm that is ultimately doing something very simple because it is so over-optimized for speed to be incomprehensible. It gives me the same feeling of a particularly arcane regex, or the [fast inverse square root algorithm](https://github.com/francisrstokes/githublog/blob/main/2024%2F5%2F29%2Ffast-inverse-sqrt.md).\n\n# Side Quest: Binary Calculator\n\nWhile making this processor, I ran into some difficulties with doing math in hex and with figuring out what integer values to use to mask specific bits. All online binary calculators are literally trash (if you know of a good one, please let me know. Google's search results are full of shitty form-based calculators). So I made a binary calculator to help with this.\n\n![](assets/fips-butterfly.png)\n\nI wanted something quick and simple that would support viewing values in base 10, 16, and 2 with convenient input methods for each. tbh I added more features than I should have (I didn't need to add bfloat16 support), but I figured I'd be using it for other projects in the future and maybe someone else might find it useful. I made it public so anyone can use it. Yes, anyone. Even you! The link is [here](https://anthonyedvalson.github.io/butterfly/)!\n\n# Programming\n\nTo compile and load programs into the system, I made a Python script. In my first iteration, this was done using pyautogui to automatically click on the screen and type in instructions one by one. This wasn’t going to work for some of the longer programs I wanted to write, so I made a script that automatically compiles the assembly, converts the instructions to the relevant Factorio signals, and generates a blueprint that I could paste into the world easily.\n\nHere's the result of my first test, where I compiled C code that generates the Fibonacci sequence, and it works!\n\n![](assets/fips-fib.mov)\n# Testing\n\nI wanted to be more rigorous with this new iteration of the processor, so I had Claude write a few thousand lines of assembly to test every instruction's edge cases and write some simple algorithms.\n\nThese would check all the behaviors of every instruction and make sure they work as expected. If there was a problem, it would print an error code and halt execution so I could look at the registers and see what happened.\n\nWhile doing this, I also developed a bunch of debugging tools that hooked into the processor internals. This included a system that shows the current and surrounding instructions, plus the ability to add breakpoints in execution. Here it is in action:\n\n![](assets/fips-debug.mov)\n\n# How to get it\n\nIf you want to try to mess around with the processor, I have a [GitHub repo](https://github.com/AnthonyEdvalson/Factorio-MIPS).\n\nIn it is the blueprint you can paste in, plus the scripts for compiling programs and the test scripts I used to verify all the instructions work.\n\n# Wrapup\n\nIt was weird doing this project again so much later, but I'm glad I did. I hadn't realized all the flaws in the original design until I revisited it. I'm much happier with version two; the solutions are a lot simpler and cleverer. It's been interesting to see how my problem-solving has changed over time.\n\nMaybe I'll revisit this project in another ten years and make a third version, but if I did, the big improvement would be to add pipelining so it runs even faster. I think I could get the clock speed up to 10 Hz with that."
  },
  {
    "color": "black",
    "width": 8,
    "code": "PRJ.097",
    "title": "Deepslate Learning",
    "category": "3D Transformers",
    "subtitle": "Large Voxel Model for minecraft",
    "chip": "blocks",
    "height": 4,
    "order": "004",
    "source": "tonyedv/004 Deepslate.md",
    "markdown": "Deepslate is an experiment I did to try and get an LLM-like model for generating 3d voxel structures.\n\nEvery now and then I have a Minecraft phase, and I love to mess around in creative mode to make giant buildings. However most of this work is pretty formulaic, a big building often has a lot of repeated motifs. Most of the time is spent establishing motifs, then the rest of the structure is just repeating it.\n\nI really like this build, but you can see that the same windows and domes are used all over the place.\n\n![](assets/deepslate-build.png)\n\n\nI figured it would be cool to have an LLM-like interface for generating these kind of buildings, you could start by making a section of the build, and then the model can extend it to create a whole structure.\n\nI also was learning about LLMs at the time, and was sad that I didn't have the GPUs and training datasets to make anything unique. So I figured this would be the perfect project. I could learn about and take advantage of existing LLM architectures, but try to generalize them to work with 3d voxels.\n\n# Dataset\n\nI knew from the start I'd need a bunch of training data. Thankfully, I have a world with a bunch of enormous buildings in it that make for a great dataset. I took my largest build and wrote some python scripts to extract a bunch of training examples from it.\n\nI could have given it multiple builds, but the total volume of this building is a few million blocks, with a bit of data augmentation this is more than enough for testing. Plus multiple buildings would be harder to learn, I wanted to give it a simple problem to solve and see how it handled it.\n\nThe building I used is this church and the big building behind it:\n\n![](assets/deepslate-build2.png)\n\n## Tokenization\n\nMinecraft has around 900 different blocks and around 5000 block states.  Plus, if you don't care about weird blocks like \"upside down curved warped wooden stairs\", you can narrow this down quite a bit. For my testing here I managed to get away with only 20-30 blocks. The one build I was training off of had a very limited block palette, and I ignored certain things like tall grass blocks to limit it further.\n\nPlus I'm betting that a Minecraft building has less complexity than written text, which means we can use a much smaller hidden dimension compared to LLMs, and fewer layers in general.\n\n# The Model Architecture\n\nI tried several different designs to see what worked best. I knew I was going with something very similar to open source LLMs at the time, with attention, feed forward networks, and positional embeddings. But the problems came from scaling to higher dimensions.\n\n## The Memory Problem\n\nMy end goal was to support a 32x32x32 region of blocks as the context window. That's 32,768 blocks. In terms of hardware I wanted to do it all local on my GTX 3080 ti, which has 12 gigabytes of RAM. This is a problem. For comparison, GPT-3 had a context window of 2,048 and required very high end GPUs, costing in the millions of dollars.\n\nThe main problem is memory. Attention is great but has O(n^2) space complexity with respect to context length. 2x the context means 4x the memory. But in 3d, this becomes O(n^6). So 2x the context is 64x the memory.\n\nOver the years there's been a bunch of tricks to try and reduce memory requirements of transformers, but all of those are meant for text. I wanted to come up with some that would take advantage of being in higher dimensional spaces.\n\n### Causal Masking in 3D is Hard\n\nCausal masking is super important for training these models efficiently. Imagine you have a sentence you are training the LLM on:\n\n| 0   | 1    | 2   | 3    | 4   |\n| --- | ---- | --- | ---- | --- |\n| Hi! | Nice | to  | meet | you |\n\nIf you wanted, you could make a bunch of training examples from this and have it guess the next word on each example:\n\n| In 0 | In 1 | In 2 | In 3 | In 4 | Output |\n| ---- | ---- | ---- | ---- | ---- | ------ |\n| -    | -    | -    | -    | -    | Hi!    |\n| Hi!  | -    | -    | -    | -    | Nice   |\n| Hi!  | Nice | -    | -    | -    | to     |\n| Hi!  | Nice | to   | -    | -    | meet   |\n| Hi!  | Nice | to   | meet | -    | you    |\n\nThis works fine, but is not the most efficient. What if we could train all 5 of these examples in a single example?\n\nInstead the training example would look like this:\n\n| In 0 | In 1 | In 2 | In 3 | In 4 | Out 0 | Out 1 | Out 2 | Out 3 | Out 4 |\n| ---- | ---- | ---- | ---- | ---- | ----- | ----- | ----- | ----- | ----- |\n| Hi!  | Nice | to   | meet | you  | Hi!   | Nice  | to    | meet  | you   |\n\nOkay, but obviously if you gave this to a model, it would just copy the inputs to the outputs. it's not going to learn to \"predict\" what comes next if the correct prediction is just handed to it.\n\nThis is where causal masking comes in. Internally, you guarantee that no information from the future inputs can be used in an output. In this case, that means output 2 is only able to \"see\" inputs 0 and 1. Causal masking is a method where you take the results of the attention heads, and \"mask\" out all the results that are passing data from right to left.\n\nGiven my strict compute budget, I have to take advantage of this optimization. My training examples have ~32,000 values, so would be a 32,000x speedup in training.\n\n### Solution 1: Swin\n\nA common approach to problems that scale poorly is to split them into small problems. I found Swin, which is used for image classification tasks and saves memory by working on smaller chunks of the space, downsampling the results, and repeating. This is good for image classification, but to be generative we need a way to produce logits so I pulled a U-net and built a decoder that pulls info from the encoder at various levels of abstraction. Here's my chart to keep track of the whole thing:\n\n![](assets/deepslate-swin.png)\n\nThis worked pretty well, but was slow to train. I hadn't added masking because I had only just realized how important it would be, and from this architecture it's pretty clear that masking would be very hard. So much data is getting mixed together and blended, and split back out. Adding masking would be difficult.\n\nPlus, even if you could add masking, how would that work? With text there's only one way to mask, from the first word to the last. But in 3D you could take an arbitrary path. I realized I would need to think about the order the cubes would be generated from the start. So I came up with a similar, but slightly different system.\n\n### Solution 2: Hilbert curves\n\nTo get the masking to work with a Swin-like architecture, I needed to try and fill up each cube region of space quickly. I think the picture explains it pretty well. This is in 2D and for a 4x4 region, but the concept generalizes to 3D easily.\n\n![](assets/deepslate-hilbert.png)\n\nYou can still use the hierarchical structure, you can see how the yellow square's value is not determined directly by all the blue and purple ones, instead it only sees the aggregated value. In this case, each transformer only works on 4 values at a time, instead of the full 16.\n\nThis has space complexity of O(n^3 * b^3), where b is the width of the subregions that attention works over. I got good results with b=4, which will reduce memory by 99.8%\n\nThis system was way more promising and had much better results, but still had some challenges. The complexity in the layers definitely made it harder to work with and a bit slower. At the time I was using Keras which probably was a bad idea, a bit too high level for these kinds of small changes.\n\nI also figured there might be a better approach that takes advantage of specific properties of the buildings I'm trying to generate, which led me to the next solution.\n\n### Solution 3: Axial Attention\n\nWhy do attention as a volume? Instead of looking at a full region, it might be good enough to just look along the axis at each point.\n\nWhat I was doing before, was using \"cubic\" attention, where you look at everything in a cube around the point (ignoring values from masking). But I wanted to explore other shapes. Ultimately, very few structures in Minecraft have diagonal structures that would require the cube to notice. The corners of the cube are quite far, and features tend to stick to the planes.\n\nSo I wanted to try axial and octahedral. With those you can use way fewer cubes to get the same coverage.\n\n![](assets/deepslate-dies.png)\n\nThe downside, is that information has to go through more steps to move diagonally. But this is a decent tradeoff. If the memory requirements are slashed, I can use a ton more intermediate layers which will allow the information to get to where it's needed, just in a few more steps.\n\nAnd with this, the optimization is big enough that there's no reason to use Swin or Hilbert curves any more. Although it would've been fun to have a practical application for 3d space filling curves, this meant I could use much more standard tools that were easier to tinker with.\n\nThe problem, was getting it to run fast.\n\n### Tony's Janky Sparse Attention\n\nThe problem, is that the standard attention systems do masking in a horribly inefficient way. They work by calculating the attention for all combination of inputs, and then masking out all the ones you don't want. This saves no memory, because you still have a huge matrix of values being calculated, but ignored.\n\nLots of people have noticed this and have made clever optimizations, but I was feeling adventurous and this was just within my capabilities. So I didn't look up any spoilers and made my own version of sparse attention.\n\n![](assets/deepslate-diag.png)\n\nIn that chart, the green diagonals are the attention mask. All the black values are calculated but discarded. To be less wasteful we should calculate the values in a way that has less empty space.\n\n![](assets/deepslate-diag2.png)\n\nSo I made a bunch of charts to understand exactly what needs to change to get the same results, but in that diagonal space.\n\n![](assets/deepslate-diag3.png)\n\nThe solution was to repeat and shift values by the diagonal offsets.\n\n![](assets/deepslate-diag4.png)\n\nAnd this works very well, memory is now O(n^3 * d), where d is the number of diagonals in the attention matrix. Ultimately I went with the axial attention, so d is quite small.\n\n# Results\n\nI unfortunately didn't reach my dream of 32x32x32 generations, but I was able to get 16x16x16 to work. The main limitation was still memory, but also training data. I could have gone a bit larger with the context, but it would have meant much fewer training examples since each would have been much larger.\n\nHere's what looks like the start of a bridge or walkway\n\n![](assets/deepslate-example2.png)\n\nThis appears to be a section of the top of a large tower, I love how much structure is going on here. I'd love to see it complete the rest of the structure.\n\n![](assets/deepslate-example3.png)\n\nAnd this seems to be the edge of a wall or bridge.\n\n![](assets/deepslate-example4.png)\n\nOverall I'm super happy with it! At the moment the output is just plotted with matplotlib, but one day I'd love to hook it up to a mod and make it more interactive. I've learned a ton about how transformers work, and had a lot of fun trying to extend it to higher dimensions. I'm definitely not out of ideas, with how to improve this, but I'm pushing against the limitations of my hardware and time. One day I'd love to revisit it."
  },
  {
    "color": "white",
    "width": 4,
    "code": "PRJ.078",
    "title": "Owl",
    "category": "Project",
    "subtitle": "Personal programming language",
    "chip": "owl",
    "height": 3,
    "order": "005",
    "source": "tonyedv/005 Owl.md",
    "markdown": "Owl is my personal programming language that I occasionally mess around with. It is a mashup of my favorite features from a bunch of languages like Python, Haskell, Go, JavaScript, and Java. Owl is designed to have a clean and compact syntax, which is great for rapid prototyping, experimentation, and messing around with programming language design.\n\n> Fun fact, in an earlier iteration of this website, the server was implemented fully in Owl, although the hosting costs were too high so I had to replace it with a static HTML page :( but it was fun to write HTTP parsers and hook the language into networking libraries.\n\nTo give you an idea of what the syntax looks like, here is [FizzBuzz](https://www.geeksforgeeks.org/fizz-buzz-implementation/):\n\n```\nFizzBuzz = (end) => {\n    i = 0\n    while i < end {\n\t    i++\n\t    s = []\n    \tif i % 3 == 0 {\n\t    \ts.Add(\"Fizz\")\n\t    }\n    \tif i % 5 == 0 {\n\t\t    s.Add(\"Buzz\")\n\t    }\n\t    print(s.Join(\"\") or i)\n\t}\n}\n```\n\n# Highlights\n\n## Pattern Matching Arguments\n\nPattern matching is something that I really like about Haskell. It removes the need for most if statements in an elegant way. Haskell has this as a result of its typing system and functional design, but I've always felt it would be a nice feature in other languages. So, Owl has a similar implementation of it. Here's an example of factorial that takes advantage of it.\n\n```\nfactorial = 0 => 1\n          | n => n * factorial(n - 1)\n\nprint(factorial(4))\n// Prints 24\n```\n\nThis is accomplished by a combination of function conditionals, and overloading. Function conditionals are expressions that decide whether a function is valid for a given set of inputs, and are generated by the parser. So, if a function contains an expression in the arguments, like the zero in `0 => 1`, the function is parsed as `$0 => 1` with a conditional `$0 == 0`. The `$0` is a dummy variable created by the parser to hold the value. Prefixing with a dollar sign is useful, because it’s illegal for the user to declare variables starting with it, guaranteeing uniqueness. Also because it looks a bit like how bash handles arguments which I find satisfying.\n\nFunction conditionals can be combined with overloading to get the desired pattern matching behavior. Unlike most languages, overloading a function is done explicitly with the overload operator `|`. It combines two functions, executing the first if its conditional is met, or the second if it isn't. Multiple overloads can be chained to make more complex branching behaviors.\n\n## Flexible Assignment\n\nFlexible assignment is a single system that handles a bunch of features. To understand it, I should first mention something unusual about Owl, which is that functions can only have one argument. `add(a, b)` looks like it's passing two arguments, but in fact, the comma there isn't a separator, it's an operator.  In Owl, the comma in `a, b` is an operator that returns the list `[a, b]`. This means the function call `add(a, b)` is identical to `add([a, b])`.\n\nWhy do it this way? At first it seems restrictive and strange, but it came from realizing that destructuring syntax like `x, y = y, x` or `[a, ...b] = list` looked similar to argument passing, so I decided to unify them.\n\n```\n// Assignment is the same as passing args.\nx, y = a, b\n\nf = (x, y) => ...\nf(a, b)\n```\n\nAfter merging the argument parsing code with the assignment code, everything became much simpler. It also meant that any improvement to arguments also applies to assignments, and the whole thing is incredibly simple, about 60 lines of code. Here are some examples of what Owl can do:\n\n```\n// Multiple assignment\nx, y = y, x\n// Multiple return values\nf = (a) => (a, a)\nx, y = f(b)\n// Spread in assignments\nx, ...xs = [1, 2, 3]\n// Spread in functions\nf = (...b) => b.Sum()\n// Nested destructuring in assignments\n[a[0], [b, ...c, d]], e.v = [1, [2, 3, 4, 5]], 6\n// Nested destructuring in functions\nf = (a, ...b, [[c], ...d]) => ...\n```\n\n# Design\n\nThe language is interpreted, and the interpreter is written in Go. Code is first processed by the lexer, which is implemented mostly with regular expressions to match tokens. The parser then converts the tokens to an abstract syntax tree, which can be used by the executor to run it.\n\nI avoided tools and frameworks meant for building languages like [ANTLR](https://www.antlr.org/) since I wanted this language to be truly my own, and I wanted to understand the underlying mechanics. So, I made them entirely from scratch in Go. The only code that I didn't write myself was the regex engine, since that seemed unnecessarily tedious.\n\n# Types\n\nThere are none. Everything in Owl is an `OwlObj`, even the primitive types like bools, strings, lists, and even functions are not distinguishable from any other objects. Owl is a duck typing language, meaning that things are distinguished by capabilities, not types. Because everything is a modifiable object, you can do all sorts of things that other languages can't. Here's an example of changing the meaning of addition for an int:\n\n```\nx = 10\nx::add = (a, b) => a - b\nprint(x + 1) // This prints 9\n```\n\nAll objects can be modified using a simple attribute system that is implemented with two dictionaries. The first is the attributes dictionary. It can store arbitrary data and is accessed with `.` much like other languages. So you can do things like `x.value = 3` and then access it later with `x.value`. This allows all objects to act as dictionaries if needed.\n\nThe other dictionary that all objects have is the \"deep attributes\". It stores the functionality that Owl will interact with, and is accessed by `::`. When there's a built-in operator being used like in `a + b`, Owl will resolve it by calling `a::add(b)`. This idea is similar to Python's [dunder methods](https://mathspp.com/blog/pydonts/dunder-methods#what-are-dunder-methods) but doesn't require the weird underscores since the attributes and language functionality of objects are cleanly separated into two dictionaries.\n\nThis allows for creating new types that can integrate seamlessly into the language. Here's an example of a basic complex number implementation:\n\n```\ncomplex = (real, imag) => {\n    c = {real: real, imag: imag}\n    c::mul = (a, b) => {\n        r = a.real * b.real - a.imag * b.imag\n        i = a.real * b.imag + a.imag * b.real\n        return complex(r, i)\n    }\n    c::str = () => {\n        if this.imag == 0 {\n            return this.real::str()\n        } else if this.real == 0 {\n            return this.imag + \"i\"\n        } else if this.imag < 0 {\n            return this.real + \" - \" + -this.imag + \"i\"\n        } else {\n            return this.real + \" + \" + this.imag + \"i\"\n        }\n    }\n    return c\n}\n```\n\nAfter adding that, it's possible to use complex numbers with the built in operators as if they were any other type:\n\n```\ni = complex(0, 1)\nprint(i * i)\n// Prints -1\n```\n\n# Syntax Highlighting\n\nAfter using the language for a while, I got tired of looking at code without any colors, so I made a custom VS Code extension to add support for the language. And now the code looks ✨fabulous✨\n\nHere's part of the JSON parser for this site before and after adding the highlighter.\n\n![](assets/owl-highlight.png)\n\nTo make this work, I had to make a second implementation of my lexer in [TextMate](https://macromates.com/manual/en/language_grammars), since that's the format that VS Code uses for syntax highlighting. It was a bit of work to implement, but the quality of life improvement was huge. The colors make syntax errors easier to spot, and also make it feel like a real language.\n\n# Optimization\n\nThe language is highly optimized — for a very specific definition of optimized. It’s optimized for the way I think about programming. I’m not trying to make the next C++, or explore category theory with an axiomatic type system. I want to mess around and have a language that works in the ways I want it to, and that’s what the language is most optimized for.\n\nAll that is to say that, in a performance sense, it’s not at all optimized. I have never run into a case where performance has been an issue, and I don’t intend to optimize it until it becomes a problem. My goal at the moment is to keep the interpreter flexible and readable so I can try new things easily. Optimization is inherently about making assumptions about a problem to solve it more efficiently, but I don’t want to be making assumptions, since they might be broken by the next feature I want to add.\n\nThis has resulted in most features of the language being represented by operators, since they’re easy to add, easy to remove, and have a generic syntax that is already well supported by the parser. This might have been obvious when I mentioned earlier that commas are operators, and so are overloaded functions. It’s a great way to keep things simple, and not get too focused on fancy syntax or ad hoc solutions to each problem.\n\n# Conclusion\n\nOwl is fun! It turned out better than I had expected, and has been a lot of fun to work on. I’m still occasionally adding new features to it as I come up with ideas. Check out the [GitHub](https://github.com/AnthonyEdvalson/owl) if you want to see more details, or want to try it out for yourself!"
  },
  {
    "color": "cblack",
    "width": 4,
    "code": "WRK.IBM",
    "title": "Weather Modeling @ IBM",
    "category": "Work",
    "subtitle": "Using ML to forecast extreme weather",
    "height": 3,
    "chip": "ibm",
    "order": "008",
    "source": "tonyedv/008 IBM.md",
    "markdown": "Extreme weather causes a lot of damage. In 2022 the US spent [165 billion dollars](https://www.climate.gov/news-features/blogs/2022-us-billion-dollar-weather-and-climate-disasters-historical-context#:~:text=Damages%20from%20the%202022%20disasters%20totaled%20%24165.1%20billion) on damages from disasters. There's a lot of value to be gained by forecasting these events in advance so governments, emergency services, companies, and citizens can better prepare themselves.\n\nWhile interning at IBM, I had the opportunity to work on an early-stage research project that addresses this issue. IBM acquired [The Weather Company](https://www.ibm.com/weather) back in 2016, and has been using massive amounts of weather data for a [wide](https://www.ibm.com/products/environmental-intelligence-suite/energy-utilities) [variety](https://www.ibm.com/products/environmental-intelligence-suite/weather-safety) [of](https://www.ibm.com/products/environmental-intelligence-suite/environmental-data) [forecasting](https://www.ibm.com/products/environmental-intelligence-suite/agriculture) [tools](https://www.ibm.com/products/environmental-intelligence-suite/risk-management). This project was an experiment to see what other things were possible with this information, as a demonstration of IBM's machine learning capabilities.\n\nWe decided to narrow things down to a specific kind of extreme weather event that we could predict easily, and decided to focus on cold snaps. These can be disastrous, particularly in the south where they aren't well equipped to handle the freezing temperatures. This decision was partly influenced by the [winter storm in Texas](https://www.ncei.noaa.gov/news/great-texas-freeze-february-2021#:~:text=On%20February%2011%2D20%2C%202021,the%20entire%20state%20of%20Texas.) that caused the state's power grid to be severely damaged. We figured we could make some progress in predicting these events and were up for the challenge.\n\n# Hasn’t This Been Done Before?\n\nThat was the question we started with, because there are plenty of tools that can be used to do long term forecasting already, so we looked into where they were falling short.\n\nWe found that all of them only predict averages, as that's what most modern forecasting systems are designed for. This is useful for farmers or government officials who want to know if it will be warmer or cooler this year, but not very useful for finding the risk of disasters, which, by their nature, are outliers.\n\nA lower mean temperature may mean that winter storms are a bit more likely, but variance contributes much more to the risk. We found that modeling this variance or “atmospheric instability” gives a much better idea of when a winter storm is likely. So we figured we could get better results than anyone else if we got really good at modeling the variance.\n\n# Design\n\n![](ibm-flow.png)\n\nWe collected data from a few different sources, a mix of IBM's proprietary data, and publicly available data from NOAA. We then did some basic processing before breaking it into the train/dev/test splits.\n\nThe model itself is fairly straightforward, PCA is used to reduce dimensionality of the weather data, then the model uses those principal components as inputs.\n\n> Fun fact, the first principal component we identified was almost identical to [El Niño](https://oceanservice.noaa.gov/facts/ninonina.html), which was a nice confirmation that everything was working properly. \n\nThe model consisted of some convolutions, and a few dense layers at the end to get the three output scalars. In between the layers are some batch norms that aren’t shown in the chart. I’d like to include what kind of layers were used, but I’m writing this post ~2 years after the fact and I don’t quite remember the specifics (I believe the convolutions were ResNet blocks, but I could be wrong).\n\nThe output `p` is the probability of a freezing temperature over the next two months. We use a standard cross entropy loss on this value.\n\nThe other two outputs `μ` and `σ` are the predicted mean and standard deviation of the temperature over the next two months. This is used with a modified categorical cross entropy loss to see how well the actual next two months of data fit the distribution. \n\n`μ` and `σ` are redundant, since `p` is the data we actually want. But in most places and times of year, the chance of freezing is zero during the summer months, so all our summer data is essentially wasted. By having the model also predict the `μ` and `σ`, the model learns general weather mechanics, even in the months where there is no chance of freezing. This is especially effective in warm areas, where freezing events are very rare.\n\n# Results\n\nThe final system was able to predict freezing temperatures with much greater confidence than our baseline. We evaluated it on the southern US and saw that we were able to predict freezing temps significantly better than the baseline. Essentially this meant that in Texas, the old system predicted cold temperatures before they occurred with 13% confidence, but ours does it with 45%. \n\nThis project was a lot of fun, I got to work with some great people and I’m very happy with how the model came out. Before this I had always thought that you would need an obscene amount of computing power or a PhD to make meaningful contributions to the field of Machine learning, but this project made me realize that this wasn’t the case. It’s enough to have a unique perspective and a solid knowledge of the underlying technology."
  },
  {
    "color": "black",
    "width": 8,
    "code": "PRJ.082",
    "title": "Lands Apart",
    "category": "Project",
    "subtitle": "Expansive Fantasy Setting",
    "chip": "dnd",
    "height": 5,
    "order": "011",
    "source": "tonyedv/011 Lands Apart.md",
    "markdown": "The Lands Apart is an open world TTRPG fantasy setting I've been iterating on over the last couple of years. I had been running campaigns with some friends and wanted to try my hand at a truly open world setting. I wanted to see what it would take to create a setting where players could go anywhere at any time, and I'd always have content prepared in advance.\n\nThe setting was largely inspired by Elden Ring. Playing that game has had a huge impact on how I view worldbuilding in general. I've never seen a game that requires the player to study architectural styles and plant cultivation techniques to piece together major historical events. Every asset in the game has had so much thought put into it. I wanted to see what would happen if I tried to apply the same level of obsessive detail in my own setting.\n\nSo, I made Lands Apart, and it definitely has a lot of detail. As of 2025 I've made:\n\n- 320,000 words of notes.\n- A Google Maps-like site for navigating the map. It has weather, time zone, and travel modeling tools.\n- 200+ points of interest to explore.\n- 40,000 years of history.\n- 16 religions.\n- 80 sessions planned out for the main quest, plus 7 major side quests\n\nFor your own sanity, I will avoid giving a deep dive into the specifics of the world. Although I'd love to blab on about my homebrew D&D setting, I know it wouldn't make for a good blog post. Instead I'll mostly be covering what it takes to create and manage a project of this scale, and some key takeaways.\n\n# Idea generation at scale\n\nThis is fairly common writing advice, but I'm going to emphasize it because it becomes absolutely critical for a project like this. You need to start with a theme or idea you are interested in exploring more deeply. It needs to be a theme that you're excited to examine from dozens of angles over a long period of time, and is fractal-like in detail.\n\nI emphasize this because it's very easy to approach worldbuilding one quest or city at a time, letting it grow organically. And you should do some of that, but if you want everything to mesh it helps to have a high level theme that ties it all together. If you don't, you lose consistency and things clash.\n\nThe theme for Lands Apart is religion. As someone who was raised atheist, and rarely interacted with religious people growing up, I was realizing that I had an underdeveloped idea about what religion means to people and how it can shape who you are. Lands Apart is an exploration of beliefs, higher purposes, and how people deal with conflicting ideals.\n\nSpecifically, I wanted to explore how belief changed in the messy ambiguity of the real world. I wanted to set up a bunch of cultures, and have their beliefs challenged - to see what happens when those ideals bend or break.\n\nHaving a theme like this is so helpful, because it means any thought you have about the core theme can be translated into content. And it's much easier to think about a topic you're already interested in than asking yourself \"what would be interesting here?\"\n\nThe overarching structure of the world came up very naturally from this thinking. I knew I'd need multiple countries with wildly different cultures that are in tension with one another. They all want unity but have become fragmented (hence the name, Lands Apart).\n\nThis is not just for thematic consistency, there's also a much more practical benefit. One highly useful bit of writing advice I keep coming back to, is that you'll always struggle to ever come up with a list of more than 10 interesting things. So if you need more than 10 interesting things, make lists of lists. So if I were to start and try to fill out 200 points of interest on a map, it all would have come out incredibly generic and repetitive. So instead I made a list of religions, broke each of those into several perspectives, broke those into ideas, and broke those down into people, places, and quests that embodied and explored them.\n\n# Balancing Lore and Gameplay\n\nHaving a hugely detailed world needs to be integrated into the story and gameplay. The story needs to not require the player to have an encyclopedic knowledge about the world, but also not be inconsequential.\n\nThis was the trickiest part, it's easy to make a needlessly detailed world, but carving a coherent story out of it can be difficult. My main takeaway from this whole process was to find the path through the world for the players to traverse. Start super small and slowly expand their world. You can introduce bigger ideas and conflict, but don’t expect the players to buy in without a reason. Map out story beats and make notes for when a concept is introduced, and when it’s necessary for the players to understand it to progress.\n\nThe part I definitely struggle with the most is letting a thing be simple. Since I have a ton of knowledge behind all the little details, I want to present them in that way. So if players ask about some world events, I’ve learned that I need to be okay with making it appear simpler than it is if it’s not the focus right now. If everything is crazy intricate, it becomes hard to direct attention to any of it.\n\nI remember that the game Firewatch would often use visual detail to direct players. So to indicate that a rock is climbable, they would make that edge of the rock have lots of little cracks and details. It's very effective for visual communication, and I believe this concept extends to verbal descriptions in TTRPGs. By describing a thing, you're implying it is important. But it can be disorienting if every NPC sounds important, or a random bit of history is explained in great detail. Players will assume they’re meant to act on everything.\n\n# The Map\n\nI'm a big fan of a good [map](https://www.youtube.com/watch?v=J5iJSXaVvao), my favorite thing to do in games like Minecraft is to travel around mapping out all the cool terrain formations. So of course I took the maps for Lands Apart very seriously. And as the primary visual for what the world looks like, I wanted to make sure it was visually interesting and useful for gameplay purposes.\n\nI also wanted to use it to communicate the scale. I plan to only show small subsections of the world when players start and slowly reveal more.\n\nAnd finally, I want the map to hook in players. Making an area that looks exciting or unusual is a great way to get players interested in exploring. I try to have major world events legible on the map because they raise good questions. Like what are the four triangle symbols? Why is the compass rose in the middle of an island? Why is there a weird purple forest?\n\nHere's the full map rendered at 1/4 resolution:\n\n![](assets/la-bigmap.jpeg)\n\n(btw when rendering at a lower res some of the positions get shifted weirdly, if you zoom in you'll def see some alignment issues)\n\nThere's also a second map for some secret areas, but I won't show it here because spoilers. But just imagine a few more continents' worth of stuff that aren't shown.\n\n## Creating the map\n\nCreating and managing a huge map over time can be challenging since you may need to go back and make little edits, or tweak colors. These are scenarios where nondestructive editing processes are super useful. In this case I used Substance Designer. It's basically an image editor, but instead of modifying image layers you build a computation tree that applies the edits for you.\n\nThere’s a few key benefits to doing it this way:\n1. You can dynamically change the resolution you render at, so you can make edits quickly at 1024x1024 resolution, then do the final render at very high resolutions \n2. It’s very easy to change things with complex dependencies. I have a single grayscale bitmap showing where land is. If I want to tweak a coastline I change a single bitmap and all the colors, coastline waves, trees, and mountains will adjust accordingly.\n3. Editing images by building out an abstract syntax tree actually feels pretty natural for me.\n\nI pushed Substance to its limits with this map. The final render produces an image of size 16384x16384, roughly the size of thirty 4K images. It takes ~80GB of RAM to render, but the size is kind of necessary to be able to read the place names.\n\nI hand painted the masks for coastlines, rivers, and biomes, but all the shading, coloring, and text was added by a very complicated substance pipeline. Here's the main part that draws the terrain:\n\n![](assets/la-map-graph.png)\n\nI also made an interactive version of the map. This is a webpage that shows the map, plus a bunch of information about weather forecasts, time zones, and pins at various points of interest. I had to write my own time zone libraries, as well as some custom weather simulations that take the climates of each region into account. But here's how the map looks in the UI:\n\n![](assets/la-interactive.png)\n\nI've mostly used the map in planning and during sessions to figure things out like weather, travel distances, and nearby points of interest to direct players towards. Although it was a bit of a pain to initially set up, it's been a very useful tool.\n\n# Note Management\n\nWith over 1,100 files, managing the notes for this project has not been easy. But thankfully I had recently picked up [Obsidian](https://obsidian.md/). It's a truly wonderful product and I use it for personal notes, at work, and even for writing this post right now. It's a dead simple markdown editor with some plugins to let you customize how everything works. \n\nWhenever talking about Obsidian, you're legally required to share your file graph, so here's mine for the Lands Apart vault:\n\n\n\n![](assets/la-note-graph.png)\n\nTo manage all this is quite difficult. Making a change is less about adding a new note, and more about becoming an expert at finding all the stuff that needs to be changed because of it. Like if I want to change a character's motivation, I need to make sure that character's note is updated, but also anywhere that trait is mentioned. This could include notes about locations, quests, or other characters.\n\nIt's useful to apply separation of concerns here. Things are much easier to maintain if you keep notes modular and self-contained. Although this is a good principle, in practice it can be difficult. If it's going to feel like a real world, things need to affect one another. This is where links can help. In general, if one file affects another, there should be link to it. That way you can follow the backlinks whenever making changes to check for consistency. This makes all the inter-note dependencies explicit.\n\nIf your notes are well maintained, you'll naturally find yourself filling in gaps. It makes it really easy to go around and add little details. Like the notes for my countries are patterned after Wikipedia, this means they include lots of silly stuff. Here's an example of one country's info card:\n\n> **Name:** Penrith\n> **Capital:** Arkstead\n> **Language:** English\n> **Religion:** Prismatic Order\n> **Demonym:** Penrithian\n> **Government:** Prismatic Kingdom, feudal\n> **Area:** 93,389 sq. mi habitable, 280,167 total\n> **Population:** 8,870,000\n> **GDP:** 289 billion (40,000 per capita)\n> **Motto:** Her Brilliance shines in us, and in all things.\n> **Time Zone:** PEN (+12)\n> **Biomes:** Temperate forest / mountains\n> \n> **Demographics:**\n> -  **Penrithian:** 72%\n> - **Shaskonese:** 13%\n> - **Lycanin:** 8%\n> - **Marithian:** 3%\n> - **Vatichian:** 2%\n> - **Aralian:** 1%\n>   \n> **National Symbols:**\n> - **National Bird:** Mistral Dove\n> - **National Animal:** Deer\n> - **National Flower:** Alpine Gentian\n> - **National Insects:** Citrine Butterflies\n> - **National Tree:** Silver Oak\n> - **National Colors:** White, blue, silver\n\nTo answer your question: yes, I did actually pick national flowers for all the countries. This was part of the overall philosophy of the project, I wanted to treat the fiction as if it were real. I didn't want to ignore those little cultural things just because they weren't gameplay relevant. I think having these details is what makes the world feel real.\n\nTo give a concrete example on how this is beneficial, I have like ~1000 words on the different designs on coins and how they've changed over time. Is this level of detail necessary? Absolutely not. But when you have to decide what a coin looks like it forces you to answer a lot of other important questions, like:\n\n1. Who is minting the coins?\n2. Do different areas use different currencies?\n3. What icons and symbols do the people minting the coins want to reinforce with their designs?\n\nThese answers aren't important to gameplay but are important for a world making sense. For example, in Lands Apart, one of the major countries collapsed a few decades ago. So players are unlikely to hear about it often. But because their coins are still in circulation, a player might get lucky and find one of these out-of-mint coins. They can be sold for a bit more than their face value, and in the process they can learn a bit about the fallen country just by looking at the iconography.\n\nThe benefit of being detailed in general is that the marginal cost of adding more detail approaches zero quickly. Like with the coins, all the questions that I had about them were already answered elsewhere. I had already known the symbols each country associated with, so it only took a few minutes to pick out designs and phrases. If you have a policy of being generally detailed, each addition isn't actually adding much information. Most of the time it's about rephrasing existing information and making everything more consistent.\n\n# Text-based adventure game\n\nTo make this setting more accessible, I've been chipping away at making a text-based adventure game in this setting. Because currently, unless you want to read a big pile of markdown documents, or you want me to run a game for you in this setting, there's no way to experience it.\n\nI'm still at the phase where I'm constantly getting sidetracked by adding new features to my bespoke text-based game engine, but it's very interesting to work on. At some point I may add a separate post just about how it works, but the main power of the system I've built is making dynamic content that adjusts based on various things like weather, time of day, player skills, etc. And as you might have guessed, the weather and time of day logic was pulled from the interactive map.\n\n![](assets/la-text.png)\n\nI've also set up some tools to leverage LLMs to help scaffold out the dialog and navigation trees based on my notes, which is super helpful given the sheer quantity of content that needs to be adapted. Plus, dialog trees are very repetitive. I’ve considered building custom dialog editing tools to make it faster but tbh, LLMs fill that gap very well and are helpful when I decide to change the dialog format and need to update hundreds of lines of dialog to the new system in a nontrivial way.\n\nAs for the writing itself, I try to not use LLMs for anything other than helping me condense my notes down. Writing this much prose is new for me, but it's where I'm learning the most.\n\n---\n\nThis project is by far the largest and most complex thing I've ever made, so it'll take a while to adapt even a fraction of it over to the new format. But I'm excited to see where it goes! It'll probably be a few years before anything is presentable, but I know that I'll learn a ton from the process."
  },
  {
    "color": "orange",
    "width": 5,
    "height": 3,
    "code": "PRJ.077",
    "title": "Latent",
    "category": "Project",
    "subtitle": "Generative Ambient Music",
    "chip": "latent",
    "order": "012",
    "source": "tonyedv/012 Latent.md",
    "markdown": "Generative AI is really cool. A number of models like [Stable Diffusion](https://stability.ai/blog/stable-diffusion-public-release) or [Midjourney](https://www.midjourney.com/home/) have popped up around image generation due to the new developments in model architectures, and massive image datasets with descriptions to train those architectures. However, music has had a harder time catching on. Music tends to be more structured than images, is more information dense, and datasets are hard to come by due to strict copyright enforcement by music distributors.\n\nAlthough there's a few passable music models out there now, there was not in 2022. At the time the models were very impressive, but a long ways off from generating music that anyone would want to listen to. Researchers seemed to be trying to solve the “Text to Music” problem, which is very difficult given how varied different music genres are. So instead I wanted to solve the “Make Music That Someone Would Actually Listen To” problem, which I believed could be done on consumer hardware and standard ML techniques. Latent is a proof of concept for this.\n\nThe biggest change I made in my approach is that I only consider generating songs that are easy to generate. Songs with vocals, many instruments, and complex structures are what cause modern generative music systems to break down. So I’m avoiding them entirely by focusing on ambient music. \n\nAmbient is a genre of music that focuses entirely on the \"texture\" of the sounds, instead of the words, melodies, or structures. It's a genre characterized by a lack of temporal structure, which makes it much easier to work with.\n\n# Design\n\nThe core of Latent is a [Variational AutoEncoder](https://en.wikipedia.org/wiki/Variational_autoencoder) (VAE). VAEs are good at taking input data, and embedding it. What I’m doing with the VAE is making an encoder for timbre space. Timbre is the music term for the texture of a sound, it’s what makes a note played on a piano sound different from the same note on a guitar. If I can represent timbres as a space, then a song can be represented as a path through that space, changing over time.\n\nBut first, the VAE requires data. So, I manually curated ~15,000 ambient music songs to pick the ones with good quality, and were suitable for timbre extraction. They mostly were obtained from scouring ambient music playlists on Spotify. I threw them all into my own playlist for later analysis (actually, I had to put them in two playlists, apparently Spotify has an 11,000 song limit on them). Each song had 3 samples extracted from it at different times, so 45,000 datapoints.\n\n> 2025 Note: I don’t love that this is how I obtained the data for this project. I did it this way because this is just for personal learning and research. Also the concerns around copyright and AI weren’t a big thing in 2022. I don’t plan on ever releasing model weights or a dataset, but if I did I would’ve considered different data collection methods, and in the future I'll avoid scraping copyrighted work, even if it is just for myself.\n\nAll the samples were manually inspected to ensure they were actually good, lots of datapoints had \"transients\" which is a catch-all term for drums and things that start abruptly. These get mangled in my dimensionality reduction systems and are explicitly not what I'm trying to model. So I listened to 45,000 audio clips and hacked up a tinder-like swiping system to keep or reject them.\n\nAll the good samples were put through dimensionality reduction. I could have just taken each audio clip and thrown it into the VAE, but each sample contains 176k data points. With only 45k samples, overfitting is likely. To overcome this I reduced the dimensionality of the data using standard signal processing techniques before any ML.\n\n## Dimensionality Reduction\n\nThis was a fun mini-project to see just how much I can compress the sounds without any ML. The goal was to turn a 2 second stereo sound clip (176,400 values) into as few parameters as possible, without losing a significant amount of information.\n\nWhen making the system, my first realization was that if we only want to model timbre, then we don’t care at all about things changing over time. The only thing that matters is the frequencies of the sound. This kind of thing is perfect for the [Fast Fourier Transform](https://en.wikipedia.org/wiki/Fast_Fourier_transform) (FFT). The FFT essentially extracts the frequencies that make up a sound, and lets you work with the frequencies instead of individual samples in time. \n\n![](assets/latent-fft.png)\n\nAfter applying the FFT, it's easy to throw out lots of information. First, is the phase information. This essentially throws out the data that tells when sounds start or end, which makes up half of the coefficients produced by the FFT. This turns the audio into a monotonous drone, which is fine because the original sound should already be a droning sound. This is equivalent to applying a heavy reverb to the audio. All the same sounds are there, but they're smeared out over time.\n\nNext, we can also throw out stereo audio, because the drone in the right ear is probably the same as the left.\n\nLastly, we can throw out most of the high frequency data. The FFT gives us intensity of each frequency from 0 hz to 22,050 hz, with 0.5 hz increments. This is a good resolution for low frequencies, but human perception of pitch is logarithmic. The difference between 20hz and 20.5hz is audible, but the difference between 20,000hz and 20,000.5hz is inaudible. So, I resampled to combine many of the high frequencies that are indistinguishable. This is called the [CQT](https://en.wikipedia.org/wiki/Constant-Q_transform), it's the same as FFT but with log scaled frequencies.\n\nThen, the values are converted to decibels and fit into the range 0 to 1, since that gives a perceptually linear output, which makes the loss functions align with human hearing.\n\n![](assets/latent-fft2.png)\n\nThis takes the data from 176,400 audio samples all the way down to 1,233 values, a 99.5% reduction. For most audio clips, there is no audible difference in the sound after being compressed in this way.\n\nI later learned this is basically what [MP3](https://en.wikipedia.org/wiki/MP3#Encoding_and_decoding) does to compress audio: use Fourier transforms along with [psychoacoustic](https://en.wikipedia.org/wiki/Psychoacoustics) optimizations. The main difference is that it can handle changing sounds, but the underlying principles are the same.\n\n## VAE\n\n1,233 values is small enough for us to work with, and the reduced dimensionality means that training the model doesn't take long at all, making experimentation quick and easy. Here is the general structure:\n\n![](assets/latent-model.png)\n\n- `UPSAMPLE(X, Y)` means that it is upsampling to X times larger, and padding with Y zeros.\n- All `CONV_1D` layers use same size padding.\n- The `ENCODE_BLOCK` is just a [ResNet block](https://d2l.ai/chapter_convolutional-modern/resnet.html) modified to work with one dimensional data. The `DECODE_BLOCK` is the same, but with inverse (transposed) convolutions. The last of each encode / decode block omits the skip connection.\n\nThe left column is the encoder, it takes our 1233 parameters describing the sound, and compresses it into a 32 dimensional vector. On the right is the decoder, which does the inverse.\n\nSince this is a VAE, the encoder outputs both a mean (μ) and log-variance (σ). When training, these are used to sample a point in a normal distribution with the given mean and log-variance, but at inference, the variance is set to 0 to remove noise. \n\nThe loss function is a combination of [KL divergence](https://en.wikipedia.org/wiki/Kullback%E2%80%93Leibler_divergence), which tries to give the latent space nice properties, like being centered at 0, and preventing values to collapse. The loss function also uses mean squared error to make sure the encoder and decoder are accurately encoding and decoding the data.\n\nTraining is incredibly fast since the input size is already very small. It only takes a few minutes to process all the samples. Once trained, the encoder can be used to map from any sound, to a timbre vector, and back. Inference is also very quick, which is great because a lot of samples are needed during song generation.\n\n# Song Generation\n\nOn its own, the VAE just lets us make a monotonous sound, but not a song. So I added a system that would draw a path in sound space. This could have been done using machine learning, but I found it was unnecessary. A bunch of points are sampled at random, and then are ranked based on some criteria. This criteria varies depending on the desired tone, I change it every time I make an album. I usually rank by pitch, volume, or weirdness (distance from the origin in latent space). From all of the samples, it picks five of the sounds, and repeats them in a structured way. The song is then generated using iterative symbol substitutions\n\nThe song structure starts with the symbol `S` which is then iteratively expanded on using the following rules, selected at random\n\n```\nS => XYXZ\nS => XYZZ\nS => XZYZ\nS => YXYZ\nS => YXZY\nS => YZXZ\nS => YZYZ\nS => ZXYZ\nS => ZXZY\nS => ZYXZ\nX => AABBAABB\nX => ABABAB\nY => CDCD\nY => CCDD\nZ => E\nZ => EE\n```\n\nTo give an example, let's say a song picked these transformations:\n\n```\nS => XZYZ\nX => ABABAB\nY => CCDD\nZ => E\n```\n\nThen applying each rule gives `S => XZYZ => ABABABZYZ => ABABABZCCDDZ => ABABABECCDDE`. The resulting song pattern `ABABABECCDDE` says which of the five sounds to use, and for how long. In this case, we start by going back and forth between the first two sounds (A and B), use point E to transition into a section where C and D alternate slowly, before going back to E at the end. \n\nThis is basically a [context free grammar](https://en.m.wikipedia.org/wiki/Context-free_grammar) but it’s being used to generate structure instead of parsing it, which gives a lot of flexibility and is very easy to modify.\n\nThis gives us a path through the latent space to make our song. However, the songs generated by this method tend to be pretty boring. Mostly because a 4 minute song with 12 steps has 20 seconds for each step. In other words, the music is just slowly changing sounds every 20 seconds. Although there's a few ambient songs that are [quite literally a single sound for 10 minutes](https://open.spotify.com/track/6y5pnIlIf86X5I6VCgqQhx?si=ae10f3f979a54547), they're the exception, and I'd like a little more variation.\n\nSo, we can spice it up with a tool I call \"the wiggler\". The wiggler takes the straight lines between points in timbre space, and coils it into a helix, giving it constant variation. The wiggling process is simple, it picks two random vectors, multiplies by sin(t) and cos(t) respectively, and adds them to the original path. \n\n> Side note: Technically, this doesn't guarantee a helix. If the random vectors are pointing in the same direction then it will move in a straight line instead of a circle. But a neat thing about high dimensional spaces is that random vectors are almost guaranteed to be at right angles to one another, so this isn't a major concern.\n\nFinally, points on the coiled path are sampled for every 1-2 seconds in the song. Each sample point in timbre space is translated into an audio clip, which is then smoothly blended to produce the final audio. There's a bit of additional processing, like fading in and out, and normalizing the volume, but then we have our audio.\n\n## Effects\n\nSometimes, the songs need a little bit more variation, and that can come from layering some nature sounds on top. This is common practice with ambient music, since it gives some nice variation to the sounds. \n\nI first tried generating these procedurally, and even made a whole framework for making procedural sound effects, but I wasn't happy with the quality in the end. So, instead I pulled some creative commons audio from [freesound](https://freesound.org/). I collected a few dozen nature sounds like wind, rain, thunder, and waves that were good quality and were in the Creative Commons.\n\nI made a simple script to load these sounds in, make them loop seamlessly, adjust their volume to be -30 LUFS, and remove any fading in or out the original clip had.\n\nThen, when a song is generated, it slowly transitions between similar effects. It adds some nice variation and makes it feel less artificial. Once the effects are layered on top of the song, then it's good to go.\n\n# Generating Albums\n\nTo generate a ~15 song album, I tend to generate around 50 songs, and quickly skim through them to see if they're any good. The VAE isn't perfect, and occasionally produces sounds that are too loud or weird, so they have to be removed. This takes about half an hour. After this, I usually have 30 that I find good and interesting. I'll give these a more thorough listening while I'm doing other work, cutting the ones that I don't like, and giving names to the ones I do. I'll also manually clean up the audio as necessary.\n\n# Results\n\n\nSee for yourself! \n\n<audio controls>  \n<source src=\"assets/shoreline.flac\" type=\"audio/flac\">  \nYour browser does not support the audio element.  \n</audio>\n\nThis one is my personal favorite. In my opinion, it's not as good as a lot of the human made stuff, but I'm pretty happy with the results. I've made 4 albums so far, and listen to them from time to time. I was definitely surprised with the variety of sounds you can get out of it, some are more meditative, others are closer to dark ambient music.\n\nMy goal was to make music that someone could listen to, and I think I accomplished that. I had a lot of fun messing with signal processing, and working with VAEs. I think the most interesting part is that the model isn't generating music, it's generating a model of timbre, and that gets used to create the music. That means you spend a lot of time focusing on improving the quality of timbre space, which is an interesting challenge.\n\nOver the years, much more sophisticated music generation models have come out, but I still enjoy how simple and lightweight my solution was."
  },
  {
    "color": "white",
    "width": 3,
    "code": "PRJ.089",
    "title": "Bolt",
    "category": "Project",
    "subtitle": "LLM Assisted Web Development",
    "chip": "bolt",
    "height": 3,
    "order": "013",
    "source": "tonyedv/013 Bolt.md",
    "markdown": "> 2025 note: this was written before coding agents were a thing, so this all seems really obvious now. Most of this tech is pretty standard now (well except the dummy components, which I still think are really neat)\n> \n> Also, Bolt is now the name of an actual product that builds websites. This is 100% a coincidence. I have no relation to that company.\n\nI've been following the development of LLMs since GPT-2, and have been surprised by how useful they are, and after trying [Copilot](https://github.com/features/copilot) I was wondering just how far these systems can go. I figured the technology was so new, that the only way to get a good idea of the capabilities was to try it myself.\n\nUltimately, I built a tool that lets you build websites using plain English and no technical expertise. Simply describe what you want, and Bolt will generate a website. It has full control over the code, allowing for complex, multi-page interactions like shopping carts.\n\n\n![](assets/bolt-cart.gif)\n\nThe above gif shows a site entirely made with Bolt. It took maybe 90 seconds of my input, plus about 10 minutes of waiting for it to make edits. The only framework used was React, all of the interactions like the cart functionality were made entirely by Bolt.\n\n\n## Goal\n\nHave a system utilizing LLMs that can write functional and valuable code. It can get input from a user, as long as it requires no technical skill.\n\n## Non Goals\n\nI don't want to make a general-purpose software developer, to keep things simple, the output will be static web pages.\n\nIt also is not designed to be production-ready, so speed and cost are not prioritized. This is meant as a proof of concept, and not a product.\n\n# Design\n\nThe user says what they want in a textbox on the Bolt interface. Bolt will then use a series of prompts, and an LLM (I'm using GPT-3.5, other LLMs are available) to make the changes.\n\nThere are a couple of parts involved. Each with a single role:\n\n- **API Server** manages everything. It launches the other parts, and has endpoints for asking the LLM to do things and reporting errors.\n- **Site** is the generated website. It uses React, and has additional code that wraps the actual website to give it additional functionality like error detection.\n- **Editor** is the part the user interacts with, it contains an iframe to the site. This is kept separate from the site so that the user can still interact with Bolt when there is a compiler error.\n- **Diode** is a command line utility for checking if a program is valid, it attempts to parse the file with `@babel/parser` and checks for common issues. This is very useful for parsing the LLM outputs.\n\nHere is roughly how they interact\n\n![](assets/bolt-chart.png)\n\n\n# Cascades\n\nCascades are the secret sauce of Bolt. It solves the problem of having a limited context length. The LLMs I'm using can only comprehend 4096 tokens at a time (A token can be a word, a parenthesis, a semicolon, etc.), which means if the website has too much code, it will fail. \n\nVector stores work okay here, but their output is selective and does not give a full description of the code, which is important for more complex edits. I tried summarization, which uses an LLM to summarize the files until they fit in the token limit. This seems like a blunt solution to me, as not all files are equally important. When editing a checkout component, you would want to know exactly how the payment processor is implemented, but the home page is much less important.\n\nTo fix this flaw, I came up with \"cascades\", which is my variant of summarization that dynamically simplifies the data based on how relevant it is to the problem at hand. The less relevant a file is, the more compressed it becomes.\n\nEach file can be simplified to one of several levels. First is `ACTUAL` which is the raw text. Then there's `DOCS` which is the generated documentation for the code. There's also `SUMMARY`, `ONE_LINE`, and `NAME`, each a more simplified version of the file than the last. Most of these use an LLM to generate them, for example, to create a `SUMMARY` version of a file, this prompt is used:\n\n```\nDescribe the code's most important features in plain english. Focus on input props (if any) and their types, as well as imported dependencies. 2 to 5 sentences.\n\n{code}\n```\n\nFiguring out what simplification to use is a classic bin packing problem. We select compression levels for each file to maximize the amount of relevant information, subject to a constraint on the number of tokens we can use. Relevant information is calculated by `relevance * information`.\n\nRelevance is a score from 0 to 1 saying how relevant a file is to the problem at hand. This is done using a combination of LLM feedback, and several heuristics generated by static analysis of the code. For example, if a js file is being edited, then one of the heuristics is to increase the relevance of imported files by +0.5.\n\nInformation is more subjective, I made a heuristic that information is halved by each level of compression, and this seems to give good results.\n\nBin packing is NP-Hard, so we probably don't want a rigorous solution. I went for the greedy approach of adding everything to the bin with no simplification. This will violate the token limit, but we can fix that by iteratively identifying the item with the least relevant information per token, and increasing its compression by one level. This is repeated until the total number of tokens is below some upper bound.\n\n# Error Handling\n\nThe LLM has no idea if the code it generates is valid. It's usually very good, but once there is an error, it cannot be resolved without reading the logs. This violates our goal for the user to not need technical expertise. So, I developed three systems to automatically detect and report errors. \n\nFirst, the API server watches the stderr of the site's server and checks for compiler errors. If it finds one, it'll send the error message to the editor UI and show a fix button. Clicking it will send the details of the error to the LLM with a standard prompt for fixing errors. This works ~80% of the time, and may take a few attempts, but I've never had it get stuck permanently.\n\nSecond, the generated website is wrapped in a React error boundary to catch all runtime errors. If these happen, it will show the same fix error UI. Here is what it looks like when a runtime error is caused by going to the book details page. \n\n![](assets/bolt-error.gif)\n\nLastly, and my personal favorite, before being deployed, the import statements are analyzed to find missing files. If there are any, it creates a \"dummy component\" in place of the missing file, which just contains a textbox asking the user what should go there. Filling it out will tell Bolt to make a new component with the new missing file path.\n\n![](assets/bolt-newcontent.png)\n\nIf all of these systems fail, or if you just don't like the output, there is a revert button that lets you roll back to previous versions of the site.\n\n# CSS\n\nLLMs are terrible with CSS. They're blind and have no way to get feedback on what designs look good. Through my testing, I've learned to give it as little control over the appearance as possible, or else it will accidentally make odd decisions like white text on a white background.\n\nTo fix this, I decided to use a CSS framework, since they can make nice looking websites with minimal CSS. The problem I encountered is that many CSS frameworks expect the developer to override margins and padding to make them presentable.\n\nSo, I did extensive testing of every CSS framework I could find, I must have tried ~15 of them. The key was to get something with good defaults, that was also popular enough that the LLM had been trained on it and knew how to use it. Bulma ended up being the best, and is what it uses now.\n\nAll of the images are pulled from Unsplash, which has a wonderful API to get a random image from a search term: `https://source.unsplash.com/random/\\<width\\>x\\<height\\>/?\\<search\\>`. I told the LLM to use URLs in that format for all images, and it seems to work great. It does pull images at random, so sometimes they aren't the most relevant. It could be improved, but it would require adding more complex systems like CLIP.\n\n# Future Improvements\n\nI'm happy with where the system is at now, it's useful enough that whenever I have a project that needs a simple HTML website, I always use Bolt first to get the broad strokes before cleaning things up myself. But, if I did come back to it, here are some things I'd want to look at.\n\n- API / backend support. Bolt actually has shown that it's capable of making API calls to a backend, but I haven't set up a backend server yet. I could add one and give it a database to let it work on full stack applications.\n- Experiment with 16k context sizes, now that OpenAI added them.\n- Use a more constrained representation of the code, more like Squarespace or WordPress. That would make it look nicer and prevent it from running into as many issues with freeform html / js (EDIT: Looks like [Wix had the same idea](https://www.wix.com/blog/wix-artificial-design-intelligence) and made a system very similar to Bolt in their editor)\n- Improve efficiency: Bolt has to read and regenerate every single file that it modifies, it would be faster and cheaper to just have it output the diffs.\n\nOverall I had a lot of fun with this one, I definitely found a lot of the rough edges with getting LLMs to act agentically and generate code but over time I can see them getting a lot better. Context management is definitely the part that needs the most work at the moment."
  },
  {
    "color": "black",
    "width": 8,
    "height": 2,
    "title": "Get in Touch",
    "subtitle": "",
    "contentInGrid": "true",
    "order": "999",
    "source": "tonyedv/999 Footer.md",
    "markdown": "<span class=\"em\"></span>\n\n[linkedin.com/in/tonyedvalson](https://www.linkedin.com/in/tonyedvalson/)\n\nSite and styes all created by me. No frameworks, no fnord, no templates. Source code on [GitHub](https://github.com/AnthonyEdvalson/Portfolio)."
  }
];
